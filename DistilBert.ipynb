{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uwoCN7plnHxC"
   },
   "outputs": [],
   "source": [
    "google_drive_path = '/content/drive/MyDrive/Uni Masters/AI6103 - DL/Project/default-settings'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KtKPAfCYnDiv"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Sum7WX3FnFU6"
   },
   "outputs": [],
   "source": [
    "drive.mount('/content/drive')\n",
    "\n",
    "# Navigate to your folder (adjust the path to match your actual folder)\n",
    "os.chdir(google_drive_path)\n",
    "\n",
    "# Verify you're in the right place\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "33JSJTHkfhrH"
   },
   "outputs": [],
   "source": [
    "!pip install evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1762875314845,
     "user": {
      "displayName": "destin ngeow",
      "userId": "13519176229864616772"
     },
     "user_tz": -480
    },
    "id": "TmWALRwTfLo3"
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import argparse\n",
    "import os\n",
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification, Trainer, TrainingArguments, EarlyStoppingCallback, DistilBertConfig, TrainerCallback\n",
    "from datasets import load_dataset\n",
    "import evaluate\n",
    "import numpy as np\n",
    "from types import SimpleNamespace\n",
    "try:\n",
    "    import matplotlib.pyplot as plt\n",
    "except Exception:\n",
    "    plt = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1762875314852,
     "user": {
      "displayName": "destin ngeow",
      "userId": "13519176229864616772"
     },
     "user_tz": -480
    },
    "id": "VDP7c1WCf0Yr"
   },
   "outputs": [],
   "source": [
    "args = SimpleNamespace(\n",
    "    override_dropout=False,\n",
    "    dropout=0.1,\n",
    "    use_early_stopping=False,\n",
    "    early_stopping_patience=2,\n",
    "    fp16=False,\n",
    "    train_batch_size=16,\n",
    "    eval_batch_size=16,\n",
    "    epochs=5,\n",
    "    weight_decay=0.01,\n",
    "    optimizer='adamw_torch'\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iIxUh0D3jKf3"
   },
   "outputs": [],
   "source": [
    "# Load AG News dataset\n",
    "print(\"Loading AG News dataset\")\n",
    "dataset = load_dataset(\"ag_news\")\n",
    "train_dataset = dataset['train']\n",
    "test_dataset = dataset['test']\n",
    "\n",
    "print(\"Creating validation split from train set (20%)\")\n",
    "split = train_dataset.train_test_split(test_size=0.2, seed=42)\n",
    "train_dataset = split['train']\n",
    "val_dataset = split['test']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G1U7gL6wjbkY"
   },
   "outputs": [],
   "source": [
    "# Load the tokenizer and model\n",
    "print(\"Loading tokenizer and model\")\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "if args.override_dropout:\n",
    "    print(f\"Overriding dropout in config to {args.dropout}\")\n",
    "    config = DistilBertConfig.from_pretrained(\n",
    "        'distilbert-base-uncased',\n",
    "        hidden_dropout_prob=args.dropout,\n",
    "        attention_probs_dropout_prob=args.dropout,\n",
    "    )\n",
    "    config.num_labels = 4\n",
    "    model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', config=config)\n",
    "else:\n",
    "    model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rvD0EjPRjOBt"
   },
   "outputs": [],
   "source": [
    "# Preprocess the data\n",
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples['text'], truncation=True, padding='max_length', max_length=128)\n",
    "\n",
    "print(\"Tokenizing datasets\")\n",
    "tokenized_train_dataset = train_dataset.map(preprocess_function, batched=True)\n",
    "tokenized_val_dataset = val_dataset.map(preprocess_function, batched=True)\n",
    "tokenized_holdout_test_dataset = test_dataset.map(preprocess_function, batched=True)\n",
    "\n",
    "tokenized_train_dataset = tokenized_train_dataset.rename_column(\"label\", \"labels\")\n",
    "tokenized_val_dataset = tokenized_val_dataset.rename_column(\"label\", \"labels\")\n",
    "tokenized_holdout_test_dataset = tokenized_holdout_test_dataset.rename_column(\"label\", \"labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3YK6Q9Oig6Z8"
   },
   "outputs": [],
   "source": [
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    eval_strategy='steps',\n",
    "    save_strategy='steps',\n",
    "    eval_steps=1000,\n",
    "    save_steps=5000,\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=args.train_batch_size,\n",
    "    per_device_eval_batch_size=args.eval_batch_size,\n",
    "    num_train_epochs=args.epochs,\n",
    "    weight_decay=args.weight_decay,\n",
    "    logging_dir='./logs',\n",
    "    save_total_limit=3,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    fp16=args.fp16,\n",
    "    greater_is_better=True,\n",
    "    optim=args.optimizer,\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "# Define a function to compute desired metrics\n",
    "def compute_metrics(p):\n",
    "    accuracy_metric = evaluate.load(\"accuracy\")\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return accuracy_metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "class TrainEvalCallback(TrainerCallback):\n",
    "    \"\"\"\n",
    "    Evaluate on the training set at epoch end and call the original compute_metrics\n",
    "    which expects a (predictions, labels) tuple. Does NOT modify compute_metrics.\n",
    "    Set eval_train_subset to an int to evaluate only first N train samples (fast).\n",
    "    \"\"\"\n",
    "    def __init__(self, eval_train_subset: int | None = None):\n",
    "        super().__init__()\n",
    "        self.eval_train_subset = eval_train_subset\n",
    "        self.trainer = None  # will set below\n",
    "\n",
    "    def on_epoch_end(self, args, state, control, **kwargs):\n",
    "        # Prefer an explicitly set trainer, fallback to kwargs\n",
    "        trainer = self.trainer or kwargs.get(\"trainer\")\n",
    "        if trainer is None:\n",
    "            print(\"TrainEvalCallback: no trainer available; skipping train eval.\")\n",
    "            return\n",
    "\n",
    "        # Choose dataset (optionally subset for speed)\n",
    "        ds = trainer.train_dataset\n",
    "        if self.eval_train_subset is not None:\n",
    "            try:\n",
    "                n = min(self.eval_train_subset, len(ds))\n",
    "                ds = ds.select(range(n))\n",
    "            except Exception:\n",
    "                # if .select not available or fails, fall back to whole dataset\n",
    "                ds = trainer.train_dataset\n",
    "\n",
    "        try:\n",
    "            # Use trainer.predict to get logits and label_ids (does not call compute_metrics)\n",
    "            pred_out = trainer.predict(ds)\n",
    "            predictions = pred_out.predictions\n",
    "            labels = pred_out.label_ids\n",
    "\n",
    "            # If label_ids is None, extract labels from the dataset\n",
    "            if labels is None:\n",
    "                # This works for HuggingFace datasets (column name \"labels\" or \"label\")\n",
    "                if \"labels\" in ds.column_names:\n",
    "                    labels = np.array(ds[\"labels\"])\n",
    "                elif \"label\" in ds.column_names:\n",
    "                    labels = np.array(ds[\"label\"])\n",
    "                else:\n",
    "                    # fallback: try to build from examples\n",
    "                    labels = np.array([ex.get(\"labels\", ex.get(\"label\")) for ex in ds])\n",
    "\n",
    "            # Call your original compute_metrics which expects a tuple (predictions, labels)\n",
    "            metrics = compute_metrics((predictions, labels))\n",
    "\n",
    "            # Prefix with 'train_' so log_history and your plotting picks up entries\n",
    "            metrics = {f\"train_{k}\": v for k, v in metrics.items()}\n",
    "\n",
    "            # Log so Trainer stores it in state.log_history (and to TB/console)\n",
    "            trainer.log(metrics)\n",
    "            print(f\"[TrainEvalCallback] epoch={state.epoch:.2f} train metrics: {metrics}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[TrainEvalCallback] failed to evaluate/train-metrics: {e}\")\n",
    "\n",
    "# Initialize Trainer\n",
    "print(\"Initializing Trainer\")\n",
    "callbacks = []\n",
    "if args.use_early_stopping:\n",
    "    callbacks.append(EarlyStoppingCallback(early_stopping_patience=args.early_stopping_patience))\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train_dataset,\n",
    "    eval_dataset=tokenized_val_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=callbacks,\n",
    ")\n",
    "\n",
    "train_eval_cb = TrainEvalCallback(eval_train_subset=None)  # or e.g. 2000\n",
    "train_eval_cb.trainer = trainer        # attach the trainer instance\n",
    "trainer.add_callback(train_eval_cb)\n",
    "\n",
    "# Train the model\n",
    "print(\"Starting training\")\n",
    "try:\n",
    "    trainer.train()\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during training: {e}\")\n",
    "    raise\n",
    "\n",
    "test_metrics = trainer.evaluate(eval_dataset=tokenized_holdout_test_dataset, metric_key_prefix=\"test\")\n",
    "print(test_metrics)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 277499,
     "status": "aborted",
     "timestamp": 1762876144186,
     "user": {
      "displayName": "destin ngeow",
      "userId": "13519176229864616772"
     },
     "user_tz": -480
    },
    "id": "d84sTU7KjlmJ"
   },
   "outputs": [],
   "source": [
    "# Visualize results\n",
    "logs = trainer.state.log_history\n",
    "\n",
    "# train loss (from step logs) + train acc (from callback at epoch end)\n",
    "tr_epochs_loss, tr_losses = [], []\n",
    "tr_epochs_acc, tr_accs = [], []\n",
    "for e in logs:\n",
    "    if \"loss\" in e and \"epoch\" in e and \"learning_rate\" in e:\n",
    "        tr_epochs_loss.append(e[\"epoch\"]); tr_losses.append(e[\"loss\"])\n",
    "    if \"train_accuracy\" in e and \"epoch\" in e:\n",
    "        tr_epochs_acc.append(e[\"epoch\"]); tr_accs.append(e[\"train_accuracy\"])\n",
    "\n",
    "# val loss/acc (from built-in eval)\n",
    "va_epochs_loss, va_losses, va_epochs_acc, va_accs = [], [], [], []\n",
    "for e in logs:\n",
    "    if \"eval_loss\" in e and \"epoch\" in e:\n",
    "        va_epochs_loss.append(e[\"epoch\"]); va_losses.append(e[\"eval_loss\"])\n",
    "    if \"eval_accuracy\" in e and \"epoch\" in e:\n",
    "        va_epochs_acc.append(e[\"epoch\"]); va_accs.append(e[\"eval_accuracy\"])\n",
    "\n",
    "os.makedirs('./results', exist_ok=True)\n",
    "\n",
    "# Plot 1: Loss vs Epoch (different color/pattern)\n",
    "plt.figure(figsize=(7,5))\n",
    "plt.plot(tr_epochs_loss, tr_losses, label='Train Loss', linestyle='-', marker='o')\n",
    "plt.plot(va_epochs_loss, va_losses, label='Val Loss', linestyle='--', marker='s')\n",
    "plt.title('Loss vs Epoch'); plt.xlabel('Epoch'); plt.ylabel('Loss')\n",
    "plt.grid(True, alpha=0.3); plt.legend()\n",
    "plt.savefig('./results/loss_vs_epochs.png', bbox_inches='tight', dpi=150); plt.close()\n",
    "\n",
    "# Plot 2: Accuracy vs Epoch (different color/pattern)\n",
    "plt.figure(figsize=(7,5))\n",
    "plt.plot(tr_epochs_acc, tr_accs, label='Train Acc', linestyle='-', marker='o')\n",
    "plt.plot(va_epochs_acc, va_accs, label='Val Acc', linestyle='--', marker='^')\n",
    "plt.title('Accuracy vs Epoch'); plt.xlabel('Epoch'); plt.ylabel('Accuracy'); plt.ylim(0.8,1)\n",
    "plt.grid(True, alpha=0.3); plt.legend()\n",
    "plt.savefig('./results/accuracy_vs_epochs.png', bbox_inches='tight', dpi=150); plt.close()\n",
    "\n",
    "# Save the trained model and tokenizer\n",
    "print(\"Saving the model and tokenizer\")\n",
    "model.save_pretrained('./results/final_model')\n",
    "tokenizer.save_pretrained('./results/final_model')\n",
    "\n",
    "print(\"Script finished successfully\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOulVdwm26y+FpvE7XKk9mC",
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
